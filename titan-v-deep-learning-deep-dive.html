<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=robots content="index,follow,noarchive"><title>Deep Learning, GPUs, and NVIDIA: A Brief Overview - PicoBlog</title><meta name=description content="To get terminology straight, machine learning, or the even more generic term AI is sometimes used interchangeably for deep learning. Technically, they each refer to different things, with ML being a subset of AI, and DL being a subset of ML."><meta name=author content="Some Person"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"PicoBlog","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"\/titan-v-deep-learning-deep-dive.html","name":"Deep learning, gpus, and nvidia a brief overview"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Reinaldo Massengill"},"headline":"Deep Learning, GPUs, and NVIDIA: A Brief Overview","description":"To get terminology straight, machine learning, or the even more generic term AI is sometimes used interchangeably for deep learning. Technically, they each refer to different things, with ML being a subset of AI, and DL being a subset of ML.","inLanguage":"en","wordCount":930,"datePublished":"2024-04-15T00:00:00","dateModified":"2024-04-15T00:00:00","image":"\/img\/avatar-icon.png","keywords":[""],"mainEntityOfPage":"\/titan-v-deep-learning-deep-dive.html","publisher":{"@type":"Organization","name":"\/","logo":{"@type":"ImageObject","url":"\/img\/avatar-icon.png","height":60,"width":60}}}</script><meta property="og:title" content="Deep Learning, GPUs, and NVIDIA: A Brief Overview"><meta property="og:description" content="To get terminology straight, machine learning, or the even more generic term AI is sometimes used interchangeably for deep learning. Technically, they each refer to different things, with ML being a subset of AI, and DL being a subset of ML."><meta property="og:image" content="/img/avatar-icon.png"><meta property="og:url" content="/titan-v-deep-learning-deep-dive.html"><meta property="og:type" content="website"><meta property="og:site_name" content="PicoBlog"><meta name=twitter:title content="Deep Learning, GPUs, and NVIDIA: A Brief Overview"><meta name=twitter:description content="To get terminology straight, machine learning, or the even more generic term AI is sometimes used interchangeably for deep learning. Technically, they each refer to different things, with ML being a …"><meta name=twitter:image content="/img/avatar-icon.png"><meta name=twitter:card content="summary"><meta name=twitter:site content="@username"><meta name=twitter:creator content="@username"><link href=./img/favicon.ico rel=icon type=image/x-icon><meta name=generator content="Hugo 0.98.0"><link rel=alternate href=./index.xml type=application/rss+xml title=PicoBlog><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css integrity=sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.5.0/css/all.css integrity=sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/highlight.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous></head><body><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><h1>Deep Learning, GPUs, and NVIDIA: A Brief Overview</h1><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Posted on April 15, 2024
&nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;5&nbsp;minutes
&nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;930&nbsp;words
&nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Reinaldo Massengill</span></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><p>To get terminology straight, ‘machine learning,’ or the even more generic term ‘AI’ is sometimes used interchangeably for ‘deep learning.’ Technically, they each refer to different things, with ML being a subset of AI, and DL being a subset of ML.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/12673/AI-Circle_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a><br>Picture from <a href=#>Intel</a></p><p>DL acquires its name from ‘deep neural networks,’ which are ultimately designed to recognize patterns in data, produce a related prediction, receive feedback on the prediction’s accuracy, and then adjust itself based on the feedback. When the feedback is based on an expected known output, this is ‘supervised learning.’ The computations occur on ‘nodes’, which are organized into ‘layers’: the original input data is first handled by the ‘input layer’ and the ‘output layer’ pushes out data that represents the model’s prediction. Any layers between those two are referred to as ‘hidden layers,’ of which deep neural networks have many hidden layers; originally, ‘deep’ meant having more than one hidden layer.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/12673/mlp_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/12673/feature_hierarchy_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a><br>Images from <a href=#>DeepLearning4J</a></p><p>These hidden layers can operate in a hierarchy of increasing abstraction so that they can extract and distinguish non-linear features even from complicated input data. A standard example is in image recognition, where initial layers look for certain edges or shapes, which inform later layers that look for noses and eyes, and layers after that might look for faces. The final layers combine all this data to make a classification.</p><p>As input data progresses forward through the model, calculations include special internal parameters (weights). At the end, a loss function is produced, representing the error between the model’s prediction and the correct value. This error information is then used in running the model in reverse to calculate weight adjustments that will improve the model’s prediction. The weights are then updated. This sequence of a forward and backward pass (or backpropagation) comprises a single training iteration.</p><p>For inferencing, the process naturally excludes a backward pass and ultimately requires less computational intensity than training the model in the first place. In that sense, inferencing also has less need for higher precisions like FP32, and models can be appropriately pruned and optimized for deployment on particular devices. However, inferencing devices become much more sensitive to latency, cost, and power consumption, especially if on the edge.</p><p>Convolutional neural networks (CNNs or convnets) and recurrent neural networks are two important subtypes of (deep) neural networks, and the previous example with image recognition would be seen as a CNN. The convolutions themselves are an operation where input data and convolutional kernel are combined to form a feature map of some kind, transforming or filtering the original data to extract features. CNNs typically are ‘feedforward’, in the sense that data flows through the layers without looping. For RNNs (and variants like LSTM and GRU), there exists a separate weight that loops back to itself after every calculation, giving the net a sense of ‘memory.’ This allows the net to make time-aware predictions, useful in scenarios like text analysis, where a network would need to remember all the previous words with respect to the current one.</p><p>As much of deep learning math could be boiled down to linear algebra, certain operations can be re-written into GPU-friendlier matrix-matrix multiplications. When NVIDIA first developed and released cuDNN, one of the marquee implementations was <a href=#>accelerating convolutions based on lowering them into matrix multiplications</a>. Among the cuDNN developments over the years is the <a href=#>'precomputed implicit GEMM'</a> convolution algorithm, which so happens to be the only algorithm that triggers convolution acceleration by tensor cores.</p><h3>A Deep Learning Renaissance: (NVIDIA) GPUs Ascendant</h3><p>Particularly for training, GPUs have become the DL accelerator-of-choice as most of these computations are essentially floating-point calculations in parallel, namely lots of matrix multiplications, with optimal performance requiring large amounts of memory bandwidth and size. These requirements neatly line up with the needs of HPC (and to a lesser extent, professional visualization), where GPUs need high precision floating point computation, large amounts of VRAM, and parallel compute capability.</p><p>Perhaps most importantly, is the underlying API and frameworks needed to utilize graphics hardware in this manner. For this, NVIDIA’s CUDA had come at the right time, just as deep learning started to regain interest, and was an easy launching point for further development:</p><ul><li>Release of CUDA & cuBLAS (2006/2007), and Tesla product line (2007)</li><li>High-profile publications and achievements</li><li>Release of cuDNN, integrated with Caffe dev branch (2014), later integrated by other DL frameworks</li></ul><p>The development of CUDA and NVIDIA’s compute business coincided with research advances in machine learning, which had only just <a href=#>re-emerged as ‘deep learning’ around 2006</a>. GPU accelerated neural network models provided orders-of-magnitude speed-ups over CPUs, and in turn re-popularized deep learning into the buzzword it is today. Meanwhile, NVIDIA’s graphics competitor at the time, ATI, was being acquired by AMD in 2006; OpenCL 1.0 itself only arrived in 2009, the same year AMD spun off their fabs as GlobalFoundries.</p><p>With DL researchers and academics successfully using CUDA to train neural network models faster, it was only a matter of time before NVIDIA released their cuDNN library of optimized deep learning primitives, of which there was ample precedent with the HPC-focused BLAS (Basic Linear Algebra Subroutines) and corresponding cuBLAS. So cuDNN abstracted away the need for researchers to create and optimize CUDA code for DL performance. As for AMD’s equivalent to cuDNN, MIOpen was only released last year under the ROCm umbrella, though currently is only publicly enabled in Caffe.</p><p>So in that sense, NVIDIA GPUs have become the reference implementation with respect to deep learning on GPUs, though the underlying hardware of both vendors are both suitable for DL acceleration.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH5zgpZsZq2hpJa7bsKMnZyeqF2hsqK%2BzaKloGWUmrKxecOirZ5nYg%3D%3D</p><hr><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><ul class=share><li><a href="//twitter.com/share?url=%2ftitan-v-deep-learning-deep-dive.html&text=Deep%20Learning%2c%20GPUs%2c%20and%20NVIDIA%3a%20A%20Brief%20Overview&via=username" target=_blank title="Share on Twitter"><i class="fab fa-twitter"></i></a></li><li><a href="//www.facebook.com/sharer/sharer.php?u=%2ftitan-v-deep-learning-deep-dive.html" target=_blank title="Share on Facebook"><i class="fab fa-facebook"></i></a></li><li><a href="//reddit.com/submit?url=%2ftitan-v-deep-learning-deep-dive.html&title=Deep%20Learning%2c%20GPUs%2c%20and%20NVIDIA%3a%20A%20Brief%20Overview" target=_blank title="Share on Reddit"><i class="fab fa-reddit"></i></a></li><li><a href="//www.linkedin.com/shareArticle?url=%2ftitan-v-deep-learning-deep-dive.html&title=Deep%20Learning%2c%20GPUs%2c%20and%20NVIDIA%3a%20A%20Brief%20Overview" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a></li><li><a href="//www.stumbleupon.com/submit?url=%2ftitan-v-deep-learning-deep-dive.html&title=Deep%20Learning%2c%20GPUs%2c%20and%20NVIDIA%3a%20A%20Brief%20Overview" target=_blank title="Share on StumbleUpon"><i class="fab fa-stumbleupon"></i></a></li><li><a href="//www.pinterest.com/pin/create/button/?url=%2ftitan-v-deep-learning-deep-dive.html&description=Deep%20Learning%2c%20GPUs%2c%20and%20NVIDIA%3a%20A%20Brief%20Overview" target=_blank title="Share on Pinterest"><i class="fab fa-pinterest"></i></a></li></ul></div></div></section></article><ul class="pager blog-pager"><li class=previous><a href=./teresa-taylor-obituary.html data-toggle=tooltip data-placement=top title="Teresa Taylor Obituary: Cause Of Death Explored As Butthole Surfers Drummer Dies Aged 60">&larr; Previous Post</a></li><li class=next><a href=./what-is-a-po-boy.html data-toggle=tooltip data-placement=top title="What Is a Po Boy? Why Is It Different?">Next Post &rarr;</a></li></ul></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href title=RSS><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted">All rights reserved
&nbsp;&bull;&nbsp;&copy;
2024
&nbsp;&bull;&nbsp;
<a href=./>PicoBlog</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.98.0</a> powered &nbsp;&bull;&nbsp; Theme <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adapted from <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js integrity=sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js integrity=sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe crossorigin=anonymous></script>
<script src=https://code.jquery.com/jquery-1.12.4.min.js integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin=anonymous></script>
<script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=https://assets.cdnweb.info/hugo/bh/js/main.js></script>
<script src=https://assets.cdnweb.info/hugo/bh/js/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script>renderMathInElement(document.body)</script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://assets.cdnweb.info/hugo/bh/js/load-photoswipe.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>